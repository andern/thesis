\documentclass[a4paper,12pt]{report}

%\usepackage{caption}
\usepackage{subcaption}

\newcommand*{\tabbox}[2][t]{%
        \vspace{0pt}\parbox[#1][3.7\baselineskip]{1cm}{\strut#2\strut}}

\usepackage{amsmath}
\usepackage{amsfonts}

\usepackage{tikz}
\usetikzlibrary{intersections,positioning,calc,arrows,shapes,
                decorations.pathreplacing,spy,automata}

\usepackage{pgfplots}
%\pgfplotsset{compat=1.7}

\usepackage{cite}

\usepackage[ruled]{algorithm2e}

\usepackage{paralist}

\usepackage{url}

\usepackage{verbatim}
\usepackage{chngcntr}
\counterwithin{figure}{chapter}
\counterwithin{equation}{chapter}
\counterwithin{table}{chapter}
\counterwithin{algocf}{chapter}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\makeatletter
\tikzset{circle split part fill/.style  args={#1,#2}{%
alias=tmp@name, % Jake's idea !!
postaction={%
insert path={
\pgfextra{
\pgfpointdiff{\pgfpointanchor{\pgf@node@name}{center}}
{\pgfpointanchor{\pgf@node@name}{east}}
\pgfmathsetmacro\insiderad{\pgf@x}
\fill[#1] (\pgf@node@name.base) ([xshift=-\pgflinewidth]\pgf@node@name.east) arc
          (0:180:\insiderad-\pgflinewidth)--cycle;
\fill[#2] (\pgf@node@name.base) ([xshift=\pgflinewidth]\pgf@node@name.west) arc
          (180:360:\insiderad-\pgflinewidth)--cycle;
}}}}}
\makeatother

\begin{document}

% print a point given by two coordinates in pt (output is in cm)
\newcommand*\printpoint[2]{(%
\pgfmathparse{0.03514598035*#1}\pgfmathprintnumber{\pgfmathresult},%
\pgfmathparse{0.03514598035*#2}\pgfmathprintnumber{\pgfmathresult})%
}

%\title{Fast Solver of a Quadratic Programming (QP) Problem}
\title{Fast Solver of Closely Related Quadratic Programming
       Problems.}

\author{Andreas Halle}
\maketitle
\thispagestyle{empty}
\newpage

\thispagestyle{empty}
\begin{abstract}
Goodtech and MathConsult have developed tools to compute the reliability of
delivery in a masked network where every link has an error rate.
This method is based on reliability theory to find actual error cases for
further analysis, and optimization theory to compute an optimal delivery
through the network for every error case.
The optimization problems are formulated as Quadratic Programming (QP)
problems.
Because the number of possible error cases increases rapidly as the size of the
network increases, it is crucial that every error case is analyzed very
quickly.
The aim is to develop a solver for effectively solving problems
\begin{inparaenum}
  \item with a problem size of 100 to 2000 variables;
  \item with sparse matrices;
  \item with positive-semidefinite quadratic terms in the objective function;
        and
  \item where the QP problem shall be solved many times with small variations
        in the constraints.
\end{inparaenum}
\end{abstract}
\newpage

%\end{@twocolumnfalse}
%]
%{
%  \renewcommand{\thefootnote}%
%    {\fnsymbol{footnote}}
%  \footnotetext[1]{University of Bergen, Department of Informatics, P.O.Box 7803, N-5020 Bergen, Norway}
%}
\setcounter{page}{3}
\tableofcontents
\newpage

\chapter{Introduction}
\label{ch:intro}
As electrical transmission systems increase in complexity, it becomes
more difficult to understand how different components in the system interact.
We often aim to increase the utilization of such systems, and with that comes
the need for good planning and operational tools.
The Transmission System Operator (TSO) is faced
with increasing requirements regarding the reliability of load
delivery, and the cost of not delivering agreed energy can be
substantial.
The need for tools to assist the TSO in analyses that can help prevent
unreliable networks is important.
Digernes et al. \cite{digernes} state:
%In \cite{digernes}, the authors state:
\begin{quote}
It is of utmost importance for the TSO to be able to perform detailed and
accurate reliability analyses; for the daily operation as well as for
future planning (comparison of reinforcement alternatives etc.). By
including power flow considerations in the calculations, the operator is
able to plan where to locate the spinning reserves to maximize the load
delivery reliability. Reliability analyses are also important for system
planning, for analyzing different alternatives for network reinforcement's
[sic] etc.\cite{digernes}
\end{quote}

Goodtech and MathConsult have developed a tool called PROMAPS
(Probability Methods Applied to Power Systems). It calculates the power
delivery as a function of demand, and the probability for undelivered
energy for each load branch in the system, and in the system as a whole.
According to Svendsen et al. \cite{trond}, a typical calculation sequence
in PROMAPS includes the following main functions:
%A typical calculation sequence in PROMAPS includes the following main
%functions\cite{trond}:
\begin{enumerate}
\item Creation of branch reliability models based on unit Markov models and
      composition and aggregation of states.
\item Selection of a subset of states containing all grid reliability states
      with a significant reliability.
\item Calculation of maximum power delivery capacity for each of the
      significant grid reliability states based on an objective function with
      constraints.
\item Calculation of expected power shortage and creation of delivery
      reliability models based on the operations composition and aggregation.
\item Calculation of delivery probability, mean visiting duration and visiting
      frequency for functioning and failed delivery states.
\item Post calculation of various auxiliary variables including economic data.
\end{enumerate}
Among these six functions, the third main function was identified as the most
time-consuming. A major part of the third main function is a call to a
quadratic programming (QP) solver\cite{trond}.

The maximum power
supply can be calculated by an objective function that represents the power
delivery profit. A typical objective function is
\begin{equation}
f(x) = - x^T \Phi D x + (c-g)^T x, \label{eq:goodtech}
\end{equation}
where $f(x)$ is the objective value ($E/s$) as a function of $x$, $x$ is the
branch power vector ($W$), $g$ is a vector containing specific power
generation costs ($E/J$), $\Phi$ is a diagonal matrix representing power loss
($1/W$), $D$ is a diagonal matrix containing specific power transmission costs
($E/J$), and $c$ is a vector containing specific power delivery price
($E/J$). The symbols in parentheses are units of measurements, where $E$
denotes the monetary unit, $J$ denotes joule and $W$ denotes
watt\cite{digernes}.

We simplify (\ref{eq:goodtech}) to
\begin{equation}
    f(x) = x^T H x + b^T x, \label{eq:obj}
\end{equation}
where $H = - \Phi D$ is a diagonal matrix that represents quadratic cost terms
($E/(W^2 s)$) and $b = c - g$ is a vector that represents linear cost terms
($E/J$) \cite{digernes}.

The maximum power delivery capacity can be defined as an optimization problem
\begin{equation}
   \min_{x} f(x)\quad\textrm{subject to}~Ax = 0,
                             ~l \leq x \leq u \label{eq:thesisqp}
\end{equation}
where $A$ is the grid configuration matrix or reduced incidence matrix, and
$l$ and $u$ are the minimum and maximum branch (lower and upper) capacity,
respectively\cite{digernes}.

If a branch with index $i$ fails, we can model that by letting
$l_i = u_i = 0$ where $l_i$ and $u_i$ denote the $i$th element of $l$ and
$u$, respectively. We refer to a branch failing as a \textit{breakdown}.
We discuss breakdowns in more detail in sections \ref{sec:instances} to
\ref{sec:subinstances} and Chapter \ref{ch:tree}.

In the next section, we present a short introduction to linear and quadratic
programming.
We then move on to Chapter \ref{ch:qp} where we present some instances of the
quadratic programming problem (\ref{eq:obj}) that Goodtech have supplied.
Afterwards, in Chapter \ref{ch:slp}, we present
an iterative optimization method based on Successive Linear Programming (SLP).
Then we move on to Chapter \ref{ch:tree}, where we present methods for
eliminating unnecessary work carried out in the third main function of PROMAPS,
and thereby improving the speed in which it is performed.
We also present implementations of all the aforementioned methods in Chapter
\ref{ch:implementation}, along with
experiments and results in Chapter \ref{ch:experiments}.

%\begingroup
%\let\clearpage\relax
\include{chapter/background/main}
\include{chapter/a_qp_problem/main}
\include{chapter/an_iterative_method/main}
\include{chapter/a_tree_representation/main}
\include{chapter/implementation/main}
\include{chapter/computational_experiments/main}
%\endgroup

\chapter{Conclusion and Suggestions to Future Work}
Goodtech and MathConsult have developed a tool called PROMAPS that calculates
the power delivery as a function of demand, and the probability for undelivered
energy for each load branch in the system, and in the system as a whole.
Among several main functions of PROMAPS, its bottleneck was pinpointed to
a call to a QP solver. The aim of this thesis was to improve the performance
of the methods initiated by this call.

We presented an iterative method based on linear programming, as the
presented data suggested that the QP problems were--- in lack of a better
word---\emph{close} to linear programs. Although this method turned out to be
slower than a commercially available alternate solver, due to the fact that the
number of iterations increases quite rapidly as the tolerance decreases, it
does stand as an alternative method, mainly because it does not require
any license fees.
It is important
to point out that the method is entirely independent of specific LP
implementations. The only requirement for implementing the method is an LP
solver. There are more available LP solvers than QP solvers in general,
but there are also more free LP solvers than free QP
solvers\cite{wikilp}\cite{wikiqp}.

Afterwards, we presented a tree-structural approach for reducing the number
of calls to the QP solver. This approach reduced the number of calls to the
QP solver by a significant amount. Depending on problem size and the number
of breakdowns, this approach caused the original method to perform from
16\% to around 70\% faster, and we have reason to believe that it would increase
even further, as $\beta$ increases. The tree-structured approach reduced the
average number of CPU-seconds used to solve a subinstance.
This method is
independent of the choice of QP solver, and since the method relies on reducing
the number of calls to the QP solver, and not increasing the speed of the
actual solver, the relative speedup will most likely remain solver independent.

\section{Future Work}
This section presents suggestions to future work regarding the methods
described in this thesis.

\subsubsection{Parallelization}
Since we are solving a huge amount of QP problems, running several QP solvers
in parallel is of interest. We suggest the parallelization of the methods
presented in this thesis as a future research topic.

%We consider the possibility of parallelizing both
%the naive method of solving all subinstances regardless of whether they are
%distinct or not, and the tree-structured approach. We begin by analyzing
%the parallelization of the naive approach.

If we are to parallelize the naive method on a distributed computer, we need to
analyze the amount of communication that is needed between processors.
Given some number of breakdowns $\beta$ and an instance $\mathcal{Q}$ with
$m$ rows and $n$ columns, we can map each subinstance of $\mathcal{Q}$ to some
$\mathcal{Q}_i$ for $i=0,1,\ldots,\sigma(\beta,n) - 1$. Each processor needs to
have a copy of the original instance $\mathcal{Q}$, which is $O(mn)$ in terms
of memory size. Given a number of processors $p$, the main processor needs to
transmit this problem to each processor, resulting in $O(pmn)$ in terms of
communication before the calculations are started. Now, each
processor solves $\frac{\sigma(\beta, n)}{p}$ subinstances, resulting in
\[
O(\sigma(\beta, n)n)
\]
in terms of communication by sending solutions back to the main processor.
Sending few, but huge blocks of data is often faster than sending many small
blocks of data.
Therefore, an alternative approach is to store all solutions on each processor,
and then transmitting them all to the main processor.
This would require
\[
O\left(\frac{\sigma(\beta, n)n}{p}\right)
\]
in terms of memory for each processor.

Further research topics may include parallelization of both the naive approach
and the tree-structural approach on both a shared memory computer and a
distributed computer.

%\onecolumn
%\newpage
%\twocolumn

\bibliography{thesis}{}
\bibliographystyle{ieeetr}

\onecolumn
\include{appendix}
\end{document}
