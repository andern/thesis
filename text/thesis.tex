\documentclass[a4paper,12pt]{report}

%\usepackage{caption}
\usepackage{subcaption}

\newcommand*{\tabbox}[2][t]{%
        \vspace{0pt}\parbox[#1][3.7\baselineskip]{1cm}{\strut#2\strut}}

\usepackage{amsmath}
\usepackage{amsfonts}

\usepackage{tikz}
\usetikzlibrary{intersections,positioning,calc,arrows,shapes,
                decorations.pathreplacing,spy,automata}

\usepackage{pgfplots}
%\pgfplotsset{compat=1.7}

\usepackage{cite}

\usepackage[ruled]{algorithm2e}

\usepackage{paralist}

\usepackage{url}

\usepackage{verbatim}
\usepackage{chngcntr}
\counterwithin{figure}{chapter}
\counterwithin{equation}{chapter}
\counterwithin{table}{chapter}
\counterwithin{algocf}{chapter}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\makeatletter
\tikzset{circle split part fill/.style  args={#1,#2}{%
alias=tmp@name, % Jake's idea !!
postaction={%
insert path={
\pgfextra{
\pgfpointdiff{\pgfpointanchor{\pgf@node@name}{center}}
{\pgfpointanchor{\pgf@node@name}{east}}
\pgfmathsetmacro\insiderad{\pgf@x}
\fill[#1] (\pgf@node@name.base) ([xshift=-\pgflinewidth]\pgf@node@name.east) arc
          (0:180:\insiderad-\pgflinewidth)--cycle;
\fill[#2] (\pgf@node@name.base) ([xshift=\pgflinewidth]\pgf@node@name.west) arc
          (180:360:\insiderad-\pgflinewidth)--cycle;
}}}}}
\makeatother

\begin{document}

% print a point given by two coordinates in pt (output is in cm)
\newcommand*\printpoint[2]{(%
\pgfmathparse{0.03514598035*#1}\pgfmathprintnumber{\pgfmathresult},%
\pgfmathparse{0.03514598035*#2}\pgfmathprintnumber{\pgfmathresult})%
}

%\title{Fast Solver of a Quadratic Programming (QP) Problem}
\title{Optimizing Performance of Solving Closely Related Quadratic Programming
       Problems.}

\author{Andreas Halle}
\maketitle
\thispagestyle{empty}
\newpage

\thispagestyle{empty}
\begin{abstract}
Goodtech and MathConsult have developed tools to compute the reliability of
delivery in a masked network where every link has an error rate.
This method is based on reliability theory to find actual error cases for
further analysis, and optimization theory to compute an optimal delivery
through the network for every error case.
The optimization problems are formulated as Quadratic Programming (QP)
problems.
Because the number of possible error cases increases rapidly as the size of the
network increases, it is crucial that every error case is analyzed very
quickly.
The aim is to develop a solver for effectively solving problems
\begin{inparaenum}
  \item with a problem size of 100 to 2000 variables;
  \item with sparse matrices;
  \item with positive-semidefinite quadratic terms in the objective function;
        and
  \item where the QP problem shall be solved many times with small variations
        in the constraints.
\end{inparaenum}
\end{abstract}
\newpage

%\end{@twocolumnfalse}
%]
%{
%  \renewcommand{\thefootnote}%
%    {\fnsymbol{footnote}}
%  \footnotetext[1]{University of Bergen, Department of Informatics, P.O.Box 7803, N-5020 Bergen, Norway}
%}
\setcounter{page}{3}
\tableofcontents
\newpage

\chapter{Introduction}
As electrical transmission systems increase in complexity, it becomes
more difficult to understand how different components in the system interact.
We often aim to increase the utilization of such systems, and with that comes
the need for good planning and operational tools.
The Transmission System Operator (TSO) is faced
with increasing requirements regarding the reliability of load
delivery, and the cost of not delivering agreed energy can be
substantial\cite{digernes}.
The need for tools to assist the TSO in analyses that can help prevent
unreliable networks is important.
In \cite{digernes}, the authors state:
\begin{quote}
It is of utmost importance for the TSO to be able to perform detailed and
accurate reliability analyses; for the daily operation as well as for
future planning (comparison of reinforcement alternatives etc.). By
including power flow considerations in the calculations, the operator is
able to plan where to locate the spinning reserves to maximize the load
delivery reliability. Reliability analyses are also important for system
planning, for analyzing different alternatives for network reinforcement's
[sic] etc.\cite{digernes}
\end{quote}

Goodtech and MathConsult have developed a tool called PROMAPS
(Probability Methods Applied to Power Systems). It calculates the power
delivery as a function of demand, and the probability for undelivered
energy for each load branch in the system, and in the system as a whole
\cite{trond}. A typical calculation sequence in PROMAPS includes the
following main functions\cite{trond}:
\begin{enumerate}
\item Creation of branch reliability models based on unit Markov models and
      composition and aggregation of states.
\item Selection of a subset of states containing all grid reliability states
      with a significant reliability.
\item Calculation of maximum power delivery capacity for each of the
      significant grid reliability states based on an object function with
      constraints.
\item Calculation of expected power shortage and creation of delivery
      reliability models based on the operations composition and aggregation.
\item Calculation of delivery probability, mean visiting duration and visiting
      frequency for functioning and failed delivery states.
\item Post calculation of various auxiliary variables including economic data.
\end{enumerate}
Among these six functions, the third main function was identified as the most
time-consuming, or more specifically in the third main function, a call to a QP
solver\cite{trond}.

The maximum power
supply can be calculated by an objective function that represents the power
delivery profit. A typical objective function is
\[
f(x) = -g - x^T \Phi D x + c^T x,
\]
where $f(x)$ is the objective value ($E/s$) as a function of $x$, $x$ is the
branch power vector ($W$), $g$ is a line vector containing specific power
generation cost ($E/J$), $\Phi$ is a diagonal matrix representing power loss
($1/W$), $D$ is a diagonal matrix containing specific power transmission cost
($E/J$), and $c$ is a line vector containing specific power delivery price
($E/J$).
The symbol $E$ is the economical unit\cite{digernes}.

A more general objective function is
\begin{equation}
    f(x) = x^T H x + b^T x, \label{eq:obj}
\end{equation}
where $H$ is a diagonal matrix that represents quadratic cost terms ($E/s$) and
$b$ is a vector that represents the linear cost terms with appropriate
sign\cite{digernes}.

The maximum power delivery capacity can be defined as an optimization problem
\begin{equation}
   \max_{l \le x \le u} f(x)\quad\textrm{subject to}~Ax = 0 \label{eq:thesisqp}
\end{equation}
where $A$ is the grid configuration matrix or reduced incidence matrix, and
$l$ and $u$ is the minimum and maximum branch (lower and upper) capacity,
respectively\cite{digernes}.

If a branch with index $i$ fails, we can model that by letting
$l_i = u_i = 0$ where $l_i$ and $u_i$ denotes the $i$th element of $l$ and
$u$, respectively. We refer to a branch failing as a \textit{breakdown}.
We discuss breakdowns in more detail later in the thesis.

In the next section, we present background material for the
main sections. We then move on to present a short data analysis of
some actual cases that Goodtech have supplied. Afterwards, we present
an iterative optimization method based on Successive Linear Programming (SLP).
Next, we present methods for eliminating unnecessary work carried out in the
third main function of PROMAPS, and thereby improving the speed in which it is
performed.
We also present implementations of all the aforementioned methods, along with
experiments and results.

%\begingroup
%\let\clearpage\relax
\include{chapter/background/main}
\include{chapter/a_qp_problem/main}
\include{chapter/an_iterative_method/main}
\include{chapter/a_tree_representation/main}
\include{chapter/implementation/main}
\include{chapter/computational_experiments/main}
%\endgroup

\chapter{Conclusion}
We started out with an initial workload, where the methods for finishing
that workload was deemed too slow. The bottleneck was pinpointed to a call
to a QP solver, and the aim was to improve the performance of the methods
initiated by this call.

We presented an iterative method based around linear programming, as the data
analyses suggested that the QP problems were--- in lack of a better
word---\emph{close} to linear programs. While this method turned out to be
quite slow, due to the fact that the number of iterations increase quite
rapidly as the tolerance decreases, it does stand as an alternative method. A
method that does not require Goodtech to pay any license fees. It is important
to point out that the method is entirely independent of specific LP
implementations. The only requirement for implementing the method is a LP
solver. There are more available LP solvers than QP solvers in general,
but there are also more free LP solvers than free QP solvers [TODO: Cite 
Wikipedia?].

Afterwards, we presented a tree-structural approach for reducing our workload.
While this approach did not improve the running time of each call to the QP
solver, it did reduce the \emph{number of calls} to the QP solver by a
significant amount. Because of fewer calls to the QP solver, it reduced the
average number of CPU-seconds used to solve a subinstance. This method is
independent of any specific QP solver, and since the method relies on reducing
workload, and not increasing the speed of the solver, the percentage of speed
increase by applying the method will most likely remain independent of solver.

\section{Future Work}
This section presents discussions of possible future work regarding the methods
described previously in this thesis.

\subsubsection{Parallelization}
Since we are solving a huge amount of QP problems, running several QP solvers
at once is of interest. We look at the possibility of parallelizing both
the naive method of solving all subinstances regardless of whether they are
distinct or not, and the tree-structural approach. We begin by analyzing
the parallelization of the naive approach.

If we are to do this parallelization on a distributed computer, we need to
analyze the amount of communication that is needed between each processor.
Given some number of breakdowns $\beta$ and an instance $\mathcal{Q}$ of of
size $m \times n$, we can map each subinstance of $\mathcal{Q}$ to some
$\mathcal{Q}_i$ for $i=0,1,\ldots,s(\beta, n)$. Each processor needs to
have a copy of the original instance $\mathcal{Q}$, which is $O(mn)$ in terms
of memory. Given a number of processors $p$, the main processor needs to
transmit this problem to each processor, resulting in $O(pmn)$ in terms of
communication before the calculations are started. Now, each
processor solves $\frac{s(\beta, n)}{p}$ subinstances, resulting in
\[
O(s(\beta, n)n)
\]
in terms of communication by sending solutions back to the main processor.
Sending few, but huge blocks of data is often faster than sending many small
blocks of data.
Therefore, an alternative approach is to store all solutions on each processor,
and then transmitting them all to the main processor.
This would require
\[
O\left(\frac{s(\beta, n)n}{p}\right)
\]
in terms of memory for each processor.

%\onecolumn
%\newpage
%\twocolumn

\bibliography{thesis}{}
\bibliographystyle{ieeetr}

\onecolumn
\include{appendix}
\end{document}
