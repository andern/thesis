There are three instances, and they all:
\begin{enumerate}
\item Have very large coefficients in the linear term compared to the
quadratic term.
\item Have that all cross-product coefficients are zero in the quadratic
term, i.e. in $x^T H x$, $H$ is diagonal.
\end{enumerate}
The instances are called---based on size---\textit{small}, \textit{large}
and \textit{vlarge}.

Figure \ref{fig:histH} shows the value distribution of non-zero elements in $H$
in the three instances. Note that among all the diagonal elements of H, more
than 50 percent of them are zero, and among the non-zero elements, most of them
are less than $10^{-2}$.
\begin{figure}[ht!]
\begin{center}
\input{include/newhistH}
\end{center}
\caption{Value distribution of non-zero elements in $H$ by column.}
\label{fig:histH}
\end{figure}
Note that no non-zero elements in the linear term in any of the instances
has absolute value less than 20. We see that the values in the linear term
are generally of much higher magnitude than the values in the quadratic term.

\begin{table}[ht!]
    \centering
    \caption{Problem size of each instance}
    \begin{tabular}{lrrr}
    Problem size & \textit{small} & \textit{large} & \textit{vlarge} \\\hline
    Rows         & 82             & 328            & 1127 \\
    Columns      & 238            & 952            & 3437 \\
    Non-zeroes A & 348            & 1392           & 4840 \\
    Non-zeroes H & 108            & 432            & 894 \\
    \end{tabular}
    \label{table:sizes}
\end{table}

Let us take a look at some hard statistics of each instance.
Table \ref{table:sizes} shows the problem size of each instance.
Table \ref{table:maxmin} shows some statistics about the non-zero elements in
the objective function for $i = 1,2,\ldots,n$ where $n$ is the number of
columns.
\begin{table}[ht!]
    \centering
    \caption{Statistics on non-zero values in the objective function of
each instance.}

    \begin{tabular}{lrr}
      & \textit{small} and \textit{large}         & \textit{vlarge} \\\hline
    $\max(h_{ii})$      & $2.9614 \times 10^{-2}$ & $4.9011 \times 10^{-2}$ \\
    $\min(h_{ii})$      & $4.9290 \times 10^{-5}$ & $1.1026 \times 10^{-5}$ \\
$\textrm{mean}(h_{ii})$ & $5.2864 \times 10^{-3}$ & $5.8984 \times 10^{-3}$ \\
    $\max(b_{i})$       & 20                      & 20 \\
    $\min(b_{i})$       & -70                     & -50 \\
    \end{tabular}
    \label{table:maxmin}
\end{table}
The rows and columns in each problem represent vertices and edges respectively.
Avid readers might notice that \textit{small} and \textit{large} are very
much alike.
This is entirely justified as \textit{large} is four \textit{small}-networks
connected, forming one large network.

For each of these instances, Goodtech wants to solve several versions
with slight variations in the input.
Goodtech wants to simulate that all combinations of edges in the network
fail, by forcing their corresponding variables to zero.
If one or more variables in an instance is forced to zero, it forms a new
instance that we refer to as a $\emph{subinstance}$ of the original instance.
This means that for each of the three instances described in this section,
they ideally want to solve a total of $2^n - 1$ subinstances. While this is
unrealistic for large $n$, it is also unrealistic that all edges in the
network breaks down.
A more realistic approach is to try to solve all subinstances with no more than
$\beta$ breakdowns.
That is, for some given $\beta$ and a problem size $n$, we solve
\begin{equation}
\sigma(\beta, n) = \sum_{j=0}^\beta {\binom{n}{j}}
\end{equation}
subinstances with less than or equal to $\beta$ breakdowns.
