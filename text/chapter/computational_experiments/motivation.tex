Throughout this chapter we refer to the implementations \texttt{construct\_clp},
\texttt{construct\_slp}, \texttt{naive\_clp} and \texttt{naive\_slp} as
\texttt{cClp}, \texttt{cSlp}, \texttt{nClp} and \texttt{nSlp}, respectively.

Now that we are finished with implementations, we are interested in knowing
how the methods perform, and how they compare with each other.
Performance can be measured in different ways, and in the next section we
discuss which experiments we run in order to assess performance.

We test our methods on the specific instances described in
Section \ref{sec:instances}, to see how they perform on instances that follow
the exact characteristics that the methods were developed for.
Testing the performance of our methods on specific instances will tell us
how it performs on those specific instances, but not how it performs in general.
While the methods developed in this thesis are specified for instances with
specific properties, the methods do not \emph{require} these properties.
To test the performance of our methods in general, we need to test them
on random instances.

In several experiments, we will test our methods on randomly generated
instances.
Unless specified otherwise, all randomly generated instances have
the following properties:
\begin{itemize}
\item We let $m = \lfloor \frac{7}{20}n \rfloor$ in order to make our random
      instances roughly as sparse as those presented in Section
      \ref{sec:instances}.
\item For each element $b_i$ in vector $b$, $b_i$ has probability $50\%$ of being 0.
\item For each diagonal element $h_{ii}$ in matrix $H$, $h_{ii}$ has
      probability $50\%$ of being 0.
\item If the elements in the two last points are \emph{not} 0, then the values lie in
      the intervals $10 \leq |b_i| \leq 70$ for $b$, and
      $10^{-5} \leq h_i \leq 10^{-1}$ for $H$, as specified in the beginning of
      Chapter \ref{ch:qp}.
\end{itemize}

Unless specified otherwise, we present all running times in experiments where
we use randomly generated instances, as the \emph{average} running time of
$10$ runs of each test, with a new random instance in each run.
The reason for using the average number of seconds, and
not the number of seconds used on the \emph{best} run, is because we do not want
one generated instance that happens to converge really fast with our algorithm,
to represent the running time in the general case.

All implementations are executed with a tolerance of $10^{-7}$, i.e.
$\epsilon = 10^{-7}$, unless specified otherwise.
The tolerance parameter for Slp is used as a stopping criteria for
the algorithm, as described in Chapter \ref{ch:slp}.
The tolerance parameter for Clp is used as a stopping criteria
for the primal-dual predictor-corrector interior point method as implemented
in Clp.

In the next section, we describe our experiments in detail.
