In this section, we present results from the experiments introduced in the
previous section.

\subsection*{Experiment 1}
Table \ref{table:expone} shows the running time in CPU-seconds required
to solve instance \textit{small}, along with $\sigma(2, 238) = 28442$ of its
subinstances, for different tolerances.
It is very clear that Slp can not
keep up with Clp's QP solver when the tolerance reaches values equal to
$10^{-5}$ and lower.
Figure \ref{fig:smalltolerance} shows plotted graphs on the logarithmic scale
of the values in Table \ref{table:expone}.

\begin{table}[ht!]
\centering
\caption{Results from experiment 1.}
\begin{tabular}{rrrrr}
$\epsilon$ & \texttt{cClp} & \texttt{cSlp} & \texttt{nClp} & \texttt{nSlp} \\ \hline
$10^{-1}$ & 45.51 & 55.61 & 72.32 & 85.51 \\
$10^{-2}$ & 46.34 & 55.89 & 73.11 & 85.51 \\
$10^{-3}$ & 51.12 & 59.04 & 75.60 & 85.28 \\
$10^{-4}$ & 52.46 & 73.79 & 77.83 & 107.39 \\
$10^{-5}$ & 54.48 & 232.53 & 81.16 & 355.47 \\
$10^{-6}$ & 65.42 & 1363.46 & 93.29 & 2022.25 \\
$10^{-7}$ & 70.78 & 6522.91 & 100.85 & 9395.92
\end{tabular}
\label{table:expone}
\end{table}

The reason for Slp being so slow with low-valued tolerances is most likely that
Slp converges really slowly as the termination condition becomes too strict
because of the low tolerance value.
\begin{figure}[ht!]
    \centering
    \input{include/small_tolerance}
    \caption{Running time in CPU-seconds required to solve \textit{small}
             and $\sigma(2, 238)$ of its subinstances, as a function of $\epsilon$.}
    \label{fig:smalltolerance}
\end{figure}
We can measure the number of Slp iterations required to solve a given instance
given some tolerance. By solving randomly generated instances where $n = 50$,
with Slp, we note the average number of iterations among ten solved
instances. Table \ref{table:expiters} shows the results from this, and we see
that the average number of iterations increases rapidly as the tolerance
becomes smaller than $10^{-4}$. This fits our prediction about why
\texttt{cSlp} and \texttt{nSlp} becomes much slower at lower tolerances.

\begin{table}[ht!]
\centering
\caption{Average number of iterations used by Slp with different tolerances
         over ten randomly generated instances.}
\label{table:expiters}
\begin{tabular}{rrrrr}
$\epsilon$ & Iterations \\ \hline
$10^{-1}$  & 1 \\
$10^{-2}$  & 1.8 \\
$10^{-3}$  & 2.2 \\
$10^{-4}$  & 3.5 \\
$10^{-5}$  & 8.6 \\
$10^{-6}$  & 23.7 \\
$10^{-7}$  & 90.1 \\
$10^{-8}$  & 223.5 \\
$10^{-9}$  & 752.6
\end{tabular}
\end{table}

\subsection*{Experiment 2}
The goal in this experiment is to see how the methods perform on static instances
of increasing size.
We learned in the previous experiment that Slp can not keep up as the tolerance
reaches values lower than $10^{-4}$, so we let $\epsilon = 10^{-4}$ to see if
Slp may keep up as $n$ increases.
Table \ref{table:eps4instances} shows the running time in CPU-seconds required
to solve the three instances.
Unfortunately, we see that even with a high tolerance, Slp can not keep up with Clp
as $n$ increases.

\begin{table}
\centering
\caption{Running times observed in Experiment 2.}
\label{table:eps4instances}
\begin{tabular}{crrr}
\textrm{Implementation} & \textit{small} & \textit{large} & \textit{vlarge} \\ \hline
\texttt{cClp}           & 0.52           & 9.55           & 76.18 \\
\texttt{cSlp}           & 0.71           & 32.88          & 585.60 \\
\texttt{nClp}           & 0.65           & 11.68          & 157.53 \\
\texttt{nSlp}           & 0.89           & 39.87          & 1173.74
\end{tabular}
\end{table}

\subsection*{Experiment 3}
Since the two previous experiments indicate that Clp performs better, we
go on to evaluate the tree-structural approach based on this solver.
Table \ref{table:expfour} shows an excerpt of the test results. The table
shows the average running time in CPU-seconds required to solve random instances
of increasing size, along with $\sigma(1, n) = n + 1$ of its subinstances. The rightmost
column shows the relative speed-up of \texttt{cClp} over \texttt{nClp}.
A table with results for all $n=100,200,\ldots,2000$ can found in Appendix
\ref{app:exp1}.
We see that the relative speed-up of \texttt{cClp} over \texttt{nClp}
increases with the instance size.
This is due to the fact that we save more time for each instance we do
\emph{not} need to solve, as $n$ increases, simply because larger instances
require more time to solve.
There are also more subinstances as $n$ grows, making room for more subinstances
that we might not have to solve.

\begin{table}[ht!]
    \centering
    \caption{An excerpt of test results from Experiment 3.}
    \label{table:expfour}
\begin{tabular}{rrrc}
    $n$ & \texttt{cClp}  & \texttt{nClp}  & Relative Speedup \\ \hline
    500 & 4.9   & 5.9   & 16.9\% \\
   1000 & 42.1  & 53.0  & 20.6\% \\
   1500 & 181.5 & 234.5 & 22.6\% \\
   2000 & 547.1 & 710.2 & 23.0\%
\end{tabular}
\end{table}

\subsection*{Experiment 4}
Table \ref{table:exptwo} shows the test results from this experiment.
The table shows the average running time in CPU-seconds required to solve
ten random instances along with $\sigma(\beta, 50)$ of its subinstances.
The rightmost column represents how many subinstances we did not have to
solve because their solutions were found in the tree.
We see that the relative speed-up of \texttt{cClp} over \texttt{nClp}
increases with $\beta$.
This is due to the fact that as the tree grows in size, the chance that
an unsolved subinstance is distinct, decreases. In fact, looking at the
rightmost column in Table \ref{table:exptwo}, we can calculate the percentage
of distinct solutions as $\beta$ increases.
There are $74.3\%, 58.3\%, 45.4\%, 32.8\%$ and $24.2\%$ distinct solutions for
$\beta$ equal to $1,2,3,4$ and $5$, respectively. This helps us clarify the reason
why the relative speed-up of \texttt{cClp} over \texttt{nClp} increases.
\begin{table}[ht!]
\centering
\caption{Results from Experiment 4.}
\begin{tabular}{rrrcr}
      $\beta$ & \texttt{cClp} & \texttt{nClp} & Relative Speedup & Skipped\\ \hline
       1  & 0.03 & 0.04 & 25.0\% & 13.6 \\
       2  & 0.64 & 0.94 & 31.9\% & 531.7 \\
       3  & 7.06 & 15.90 & 55.6\% & 11391.3 \\
       4  & 77.59 & 188.83 & 58.9\% & 168913.5 \\
       5  & 586.54 & 1758.23 & 66.6\% & 1795250.7 \\
       6  & 3115.83 & 0      & 0      & 14283962.0
\end{tabular}
\label{table:exptwo}
\end{table}

Figure \ref{fig:constructincb} shows a plot of the average number of
CPU-seconds required to solve one subinstance, as a function of $\beta$.
We see that as $\beta$ increases, the number of seconds required to solve
one subinstance decreases in the case of \texttt{cClp},
but for \texttt{nClp}, it does not change much. This behavior is very
much expected, especially considering our earlier assessment in this
experiment.

\begin{figure}[ht!]
    \centering
    \input{include/construct_incb}
    \caption{Average running time in CPU-Seconds required to solve one subinstance,
             as a function of $\beta$.}
    \label{fig:constructincb}
\end{figure}
\begin{comment}
%\subsection*{Experiment 5}
\begin{table}[ht!]
\centering
\caption{Ignore this table at the moment. Unfinished possible experiment.}
\begin{tabular}{rrrr}
    $\beta$ & \texttt{cClp} & \texttt{cSlp} & Skipped \\ \hline
     1  & 0.01          &               & 6.2 \\
     2  & 0.08          &               & 131.5 \\
     3  & 0.48          &               & 1237.3 \\
     4  & 2.16          &               & 9579.5 \\
     5  & 6.23          &               & 50825.9 \\
     6  & 18.52         &               & 201651.9 \\
     7  & 70.16         &               & 567071.6 \\
     8  & 202.11        &               & 1462074.6 \\
     9  & 379.84        &               & 3351206.6 \\
     10 & 807.85        &               & 6468142.0 \\
     11 & 1997.67       &               & 10606968.5
\end{tabular}
\end{table}
\end{comment}
